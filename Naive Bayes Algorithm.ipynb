{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNYKKImc41iAqiW/c8dC48a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"o0j961KfeSLt"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# **NAIVE BAYES ALGORITHM**"],"metadata":{"id":"aTlewheYpl26"}},{"cell_type":"markdown","source":["**TYPES OF NAIVE BAYES ALGORITHM**"],"metadata":{"id":"gVjdt6DSqfwJ"}},{"cell_type":"markdown","source":["**Gaussian Naive Bayes :** This type of Naive Bayes is used when variables are continuous in nature. It assumes that all the variables have a normal distribution. So if you have some variables which do not have this property, you might want to transform them to the features having distribution normal. The normal distribution has several key features alid properties that define it.\n","\n","\n","First, Its mean (average), median (midpoint), and mode (most frequent observation) are all equal to one another.\n","\n","**Normal distribution**, also known as the **Gaussian distribution**, is a probability distribution that is symmetric about the mean, showing that data near the mean are more frequent in occurrence than data far from the mean. In a normal distribution the mean is zero and the standard deviation is 1.\n","\n","All kinds of variables in natural and social sciences are normally or approximately normally distributed. Height, birth weight, reading ability, job satisfaction, or SAT scores are just a few examples of such variables.\n","\n"],"metadata":{"id":"OHSj066Jpsxn"}},{"cell_type":"markdown","source":["**Multinomial Naive Bayes :** Suppose you have a text document and you extract all the unique words and create multiple features where each feature represents the count of the word in the document. In such a case, whave a frequency as a feature. In such a scenario, we use multinomial Naive Bayes.\n","\n","\n"],"metadata":{"id":"5S6QtR9dqcmM"}},{"cell_type":"markdown","source":["**Bemoulli Naive Bayes :** This is used when features are binary. So, instead of using the frequency of the word, if you have discrete features in 1s and Os that represent the presence or absence of a feature. In that case, the features will be binary and we will use Bernoulli Naive Bayes.\n","\n"],"metadata":{"id":"VMLtqp05rU8m"}},{"cell_type":"code","source":[],"metadata":{"id":"KIq1vWdmrl-p"},"execution_count":null,"outputs":[]}]}